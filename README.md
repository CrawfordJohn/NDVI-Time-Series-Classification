# NDVI-Time-Series-Classification
Classifying deciduous and evergreen trees based on time series with ROCKET and ridge classifier

Electricity is an essential part of society as we know it today. People use electricity for almost everything, washing their laundry, cooking their food, and heating and lighting up their homes. Because of this, when power outages occur, it can cause a great deal of problems for the people affected. One common cause of power outages are collapsing trees during storms crashing down onto the power lines and conducting all the electricity away from the powerlines. These power outages usually occur due to these taller trees being too close to the lines, so it can be useful information to determine possible risky areas where this could occur so communities can prepare and prevent these trees from causing power outages. Being able to determine the type of trees that are near power lines can be valuable information since each type of tree has a different risk level. This classification branch starts with classifying trees into two different groups, deciduous trees (trees that lose their leaves in the winter) and evergreen trees. When observing trees in person, it may seem relatively easy to distinguish between the needle-shape of evergreen leaves and the distinct wide flat leaves that are found on deciduous trees. This distinction is made even easier during the winter and fall months when the leaves on the deciduous trees are turning a variety of colors or simply falling off. While this classification process may seem easy to do in person, it is a grueling and repetitive task to visit every tree in a specific area to classify it by hand. Using satellite data, we can avoid this laborious process and automate a way to differentiate between these two main types of trees. 
	The Normalized Difference Vegetation Index (NDVI) is a measurement of the vegetation (greenery) in a specific area using satellites. The satellites collect information on the near-infrared light and the red light in certain areas and take the difference in order to calculate the NDVI. Vegetation reflects this near-infrared light and it absorbs red light, so if there’s more near-infrared light and less red light, we will get a greater NDVI value. NDVI values are standardized between the values of -1 and 1, with each value allowing one to assume a different scene classification (water, vegetated, not-vegetated, cloud-cover). Using satellite data, we can create a time series using this information at specific locations to observe the changes in vegetation over the whole year. Since deciduous trees lose their leaves during the winter months, they therefore register lower on the NDVI index, so they end up having a time series that has a spike in the spring and a steep drop off in the fall. Evergreen trees don’t lose their leaves, so they have a relatively static NDVI value all year round. With a time series classification model, we can use a group of these different time series to train a model that can predict the type of tree just based on the time series. However, there are a couple of roadblocks before the time series is sent straight to model. 
	The time series used for this model has a frequency of 5 days and has data from May of 2018 to June of 2021. The data comes with a timestamp of unix time in milliseconds, which can easily be converted into a datetime format using pandas. Those specific dates can then be used to create a day of year column to allow the NDVI values to be observed as a seasonal yearly trend. The first step in preparing this time series for any time series model is to find and drop any outliers observed in the data. The first part of this step is pretty easy, just filter the Scene classifications to values of 4 or 5 (vegetated or not vegetated). However, this scene classification method is not 100% accurate, and there can still be some outliers that need to be cleaned up. Since the time series for deciduous trees comes in a bimodal fashion, we cannot simply take the mean and standard deviation of the entire time series to determine outliers. A rolling window method needs to be used, where the mean and standard deviation are calculated based on a specific value of previous data points. Using a baseline of 2 standard deviations away from the mean to determine outliers, a rolling window of 4 data points seemed to be adequate for removing outliers as shown by the before and after graphs. 
	After these outliers have been removed from the time series, there is another problem that arises because of this. Since the outlier detection deleted some of the points at the ends of each time series, they no longer have the same length of rows. For the model chosen to train and classify these time series (explained later), each time series must have the same shape array, so the time series were needed to be cut down to the minimum number of rows of all of the files after the outlier detection. The other missing values in between the first and last value don’t matter for this, as these data points can be repainted with simple interpolation. The indices in the previous data frame taken before the outliers were removed can be cycled through to find which indices were taken out and need to be interpolated for. Once this list is created, the scipy function interp1d can be used to take a simple interpolation between the last and next point for those missing values. These interpolated values can then be placed into a dataframe to combine with the outlier-removed dataframe to complete the reconstructed time series.
	Now that our time series has outliers removed and replaced by interpolated values, it can now be inputted into a time series classifier model. For this situation, Rocket transform was used from the sktime package with a RidgeClassifier. Rocket uses a set number of random kernels to create different feature maps for each different time series classification. (more info: https://www.sktime.org/en/stable/examples/rocket.html)  These features are then passed to train the RidgeClassifier with logistic regression. This ridge classifier works by converting the target values to -1 and 1 and using the inputted regression to determine which class the time series belongs to (more info: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html). In order to prepare Rocket to train the RidgeClassifier, all of the time series need to be formatted so that the entire time series is an array with each array being one cell in a two column dataframe. Each of the time series’ classifications should also be placed into a separate numpy array, with the index lined up with its corresponding time series on the overall DataFrame. Since all of the given data was time series for deciduous trees, it was necessary to create a simulated evergreen tree time series with a static value and a little bit of noise to make it not just a straight line. For this model training, 3 deciduous and 3 evergreen time series were used, and 1 of each category was used for the test dataframe. It would be ideal to have more data to truly assess the model accuracy and some actual evergreen time series, but with what I gave the model, it classified both of the test time series correctly.  
